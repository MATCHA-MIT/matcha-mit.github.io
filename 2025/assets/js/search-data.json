{"0": {
    "doc": "Cache Attacks",
    "title": "Cache Side Channel Attacks Lab",
    "content": "Mid-checkpoint Date: Feb 27; Due Date: Mar 11; Last Updated Date: Jan 22 . ",
    "url": "/2025/labs/cache.html#cache-side-channel-attacks-lab",
    "relUrl": "/labs/cache.html#cache-side-channel-attacks-lab"
  },"1": {
    "doc": "Cache Attacks",
    "title": "Table of Contents",
    "content": ". | Mid-checkpoint Date | Introduction | Part 1: Gathering Information (15%) . | Part 1.1: Determining Machine Architecture | Part 1.2: Timing a Memory Access | . | Part 2: Capture the Flag with Flush+Reload (25%) | Part 3: Capture the Flag with Prime+Probe (35%) . | Before Attacking: Cache Addressing | Using Hugepage | Implementing the Attack: Prime+Probe | . | Part 4: Dead Drop – An Evil Chat Client (25%) | . Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . Log in to our lab machine that you are assigned, unicorn.csail.mit.edu for example, via ssh by running ssh username@unicorn.csail.mit.edu. You will complete this lab primarily in C. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). Mid-checkpoint Date . This lab is challenging, so we strongly encourage you to start early. We highly recommend completing Parts 1–2 by the mid-checkpoint date (Feb 25). ",
    "url": "/2025/labs/cache.html#table-of-contents",
    "relUrl": "/labs/cache.html#table-of-contents"
  },"2": {
    "doc": "Cache Attacks",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Reverse engineer the cache configuration on our lab machine. | Solve two CTF (capture-the-flag) puzzles using cache-based side channels. | Build a covert channel to send and receive arbitrary messages using cache-based side channels. | . In this lab, you will learn how to interact and manipulate fine-grained cache states in real hardware. Real, commercial hardware is a black box to us. To be able to mount a cache attack, we need to leverage our computer architecture knowledge to infer how a cache behaves for a sequence of instructions. Making the attacker’s life more difficult, real-world caches are far more complex than the toy example caches that we learned in the classroom. After completing this lab, you will hopefully get a glimpse of the complexity of these hardware features. Getting Prepared Before You Start . You will program in C throughout this lab. C is a low-level language that gives you more control over the hardware compared to high-level languages. Programs written in C can be directly compiled into machine code, and directly executed on the hardware without other abstraction layers. When working on microarchitectural attacks, having a high degree of control over the exact instructions being executed is essential. If you are not familiar with C, we highly recommend participating in the “CTF of C Programming” recitation. You can also get yourself familiar with C syntax by looking at the recitation materials. You will need to think about how the cache works while working on this lab. Our lab machine is huge (with 96 cores) and has a relatively complex cache hierarchy. We highly recommend you also attend the “Cache Attack” recitation, where we give an overview of the processor architecture of our lab machines. Knowing the overall organization may help you think and debug. You can also look up relevant information following the recitation materials (link will be available soon). Setting Up Your Environment . You will run your attacks using two CPU cores on the lab machine. Every student will get a different pair of CPUs such that your programs do not interfere with each other. Each pair of CPUs provided is a pair of SMT (aka, Simultaneous MultiThreading) cores. These two “logical cores” map to the same physical core and share multiple hardware resources associated with that core, such as private L1 and L2 caches. Configuration . After logging into the lab machine and cloning your repo, you must modify the SENDER_CPU and RECEIVER_CPU variables in cpu.mk to your assigned CPUs. You have to do so before running code for any portion of this lab! Only after you have configured these variables, you can remove the $error$ line from cpu.mk. Double check that you have set these values correctly. Do not use VS Code’s remote ssh plugin to connect to the server! This plugin can introduce a large degree of noise, and is likely to cause your attack to fail. ",
    "url": "/2025/labs/cache.html#introduction",
    "relUrl": "/labs/cache.html#introduction"
  },"3": {
    "doc": "Cache Attacks",
    "title": "Part 1: Gathering Information (15%)",
    "content": "Before we begin, think – what is the first step when planning to attack a system? We first need to gather information about the system’s attributes. This rule applies to attacking software, hardware, and even in real-life on non-computing systems! For example, if you wanted to plan a bank robbery, you would first need to figure out the floorplan of the bank, the locations of safes and security cameras, etc. In this part of the lab, you will see a few practical approaches people use to gain detailed microarchitecture information of commodity hardware. You will further get familiar with some common techniques and instructions that we can use to measure execution latencies on processors, which will help you mount your attacks later on. Part 1.1: Determining Machine Architecture . The simplest way to gather hardware information is to use existing public system interfaces and documentation. Here is a list of commands that can be used to determine machine architecture information on Linux. | lscpu: Provides information on the type of processor and some summary information about the architecture in the machine. | less /proc/cpuinfo: Provides detailed information about each logical processor in the machine. (Type q to exit.) | getconf -a | grep CACHE: Displays the system configuration related to the cache. This will provide detailed information about how the cache is structured. The numbers that are reported using this command use Bytes (B) as the unit. | . In addition, WikiChip is a good source of information, as it provides information specific to each processor and architecture. You can find a detailed architecture description of our lab machines (Intel Cascade Lake processors) here, which additionally provides the raw latency value for accessing different levels of caches. 1-1 Discussion Question . Fill in the blanks in the following table using the information you gathered about the cache configuration of the lab machine. You should be able to directly obtain the information for the first 3 blank columns using commands above. You will need to derive the number of sets using what you have learned about set-associative caches in 6.1910[6.004]. Raw latency can be obtained from the WikiChip document. The line size of L1 data cache has been filled in for you. | Cache | Cache Line Size | Total Size | Number of Ways (Associativity) | Number of Sets | Raw Latency | . | L1-Data | 64 Bytes |   |   |   |   | . | L2 |   |   |   |   |   | . | L3 |   |   |   |   |   | . Part 1.2: Timing a Memory Access . The information you can get from public sources can be limited, as hardware companies would not like to disclose all of their proprietary design details to general users and potential competitors. An alternative way to gather information is to reverse engineer the processor by running some very carefully designed instruction sequences on the processor and observing their behaviors. In this part, you will try to reverse engineer the latencies for accessing the cache hierarchy. Specifically, we would like to know how long it takes to access cache lines that are located in the (a) L1 data cache, (b) L2 cache, (c) L3 cache, and (d) the DRAM. The Reverse Engineering Plan . To measure the L1 latency, we can perform a load operation on a target address to bring the corresponding cache line into the L1 data cache. Then, we measure the access latency by counting the cycles it takes to re-access the same target address using measure_one_block_access_time. We have provided this code for you, and you can compile the starter code using the command make, and then run it with make run. Your task is to complete the main function in main.c to populate the three arrays dram_latency, l2_latency, and l3_latency. We suggest you start with measuring DRAM latency, since measuring DRAM latencies is the easiest. You can leverage the instruction clflush to place the target address to DRAM. Measuring L2 and L3 latencies is slightly more complex. To measure the L2 latency, we need to place the target address in the L2 cache. However, simply accessing the target address will make the address reside in the L1 cache. Therefore, need to access other addresses to evict the target address from the L1 cache. Thus, you first need to access the line to bring it into L1, then create cache conflicts to evict it into L2. When it comes to measuring the L3 latency, you need to similarly create cache conflicts to evict the cache line from both the L1 cache and the L2 cache. Helper Functions . Before you start, make sure you familiarize yourself with C syntax and several useful x86 instructions. Read the code in utility.h and understand the following functions. | rdtscp and rdtscp64: Read the current timestamp counter of the processor and return a 32-bit or 64-bit integer. | lfence: Perform a serializing operation. Ask the processor to first complete the memory loads before the lfence instruction, then start issuing memory loads after the lfence instruction. Other variants of fences exist, such as sfence and mfence. | measure_one_block_access_time: Measure the latency of performing one memory access to a given address. | clflush: Flush a given address from the cache, evict the line from the whole cache hierarchy so that later accesses to the address will load from DRAM. | print_results_plaintext and print_results_for_visualization: Print the collected latency data in different formats. The default Makefile compiles two binaries: main uses print_results_plaintext, while main-visual uses print_results_for_visualization. | . Pointer Arithmetic . Pointer arithemetic operations, such as new_ptr = old_ptr + 1, means moving the pointer forward by one element. For different types of pointers whose element size is different, the actual bytes being moved can be very different. For example, given a uint8_t pointer, since each element is 1 byte, +1 means moving the pointer foward by 1 byte. However, +1 of a uint64_t pointer means moving the pointer forward by 8 bytes. We highly suggest to use uint8_t pointers to make your address calculation easier and avoid introducing addressing mistakes. Further details about common C/C++ constructs can be found in the C Programming Recitation. Visualization Support . Microarchitectural side channels are notoriously noisy, and it is common to get inconsistent latency results from run to run. To combat noise, the most commonly used methodology is to repeat the experiments and plot the distribution of the observed latencies. We have provided two Python scripts to help you launch multiple measurements and visualize these measurements. To install python packages used in these two scripts, please run: . python3 -m pip install matplotlib tqdm . | run.py: A python script that will generate 100 runs from the main-visual binary. It will create a folder (if one doesn’t already exist) called data, and it will store all the generated samples there in json format. The script will overwrite the folder if it already exists. | graph.py: A python script that will plot the histogram of the samples collected from run.py. It will read the JSON files from the folder data and generate a pdf file of the histogram in a folder called graph. | . Expected Outcome . When grading we will not check the exact latency numbers generated by your code, since different implementations can yield different latency numbers. For example, it is unlikely that your L1 latency will match the L1 raw latency number from WikiChip. This is because our measurement involves extra latency introduced by the lfence instructions. Besides, other factors such as the frequency of the core and prefetch configurations of the cache can also affect the latency. If you want to check whether you are on the right track, you should look for the following patterns in your visualized plot. We also include an example plot below. | There are distinct peaks for DRAM, L3, and L2 latency. | The L1 and L2 latency do not need to be distinguishable. | . A reference memory latency distribution plot . 1-2 Exercise . Fill in the code in main.c to populate the arrays dram_latency, l2_latency, and l3_latency. DO NOT take latency measurements while also printing. Instead, measure then print. When debugging your code, it is tempting to write code like this, which we call “measuring while printing”. for i in l1_cache: # Observe some aspect of the cache state val = time_access(cache line i) # In the same measurement loop, print the observed value out! printf(\"The cache took %d cycles\", val) # Now we go to the next interation and measure again . Do not do this! We are no longer in the regular world, we are in the microarchitectural world, where each assembly instruction counts! . What do we mean by this? Under the hood, a “simple” call to printf involves executing a huge number of instructions. When you call printf, you are going to go to the libc library, doing some string processing, and eventually making a system call into the kernel (so, the entire CPU performs a context switch, and does who knows what else). Think about how many cache lines this call to printf will need to read/write – printing anything is a destructive action to the state of the cache. Instead, you should measure then print. We suggest structuring your code like this: . uint64_t measurements[NUM_THINGS_TO_MEASURE] # Measure for i in l1_cache: measurements[i] = time_access(cache line i) # Then, print :) print(measurements) . Tips for Reliably Triggering Cache Evictions . The following tips may help you if you get stuck when you could not observe differences between the L2 and L3 cache latency. A common pitfall is not properly evicting the target address from the L1/L2 cache due to various reasons. | Cache Line Size != Integer Size: To begin with, you should be careful with the the mismatch of access granularities. The smallest operational unit in cache is the cache line, which is larger than the size of an integer. Accessing two integers that fall into the same line (more precisely, that fall within the same cache line size aligned region of memory) will result in a cache hit, and won’t cause an eviction. So make sure to use eviction addresses that do not map to the same cache line when attempting to evict. | Advanced Cache Replacement Policy: The cache replacement policy in modern processors is more advanced than the simple policies that we learned in class, and is often not completely known to us. It may intelligently decide to keep a target address in the cache, rather than evicting it. To combat the advanced replacement policy, we suggest accessing the eviction buffer multiple times. | Virtual to physical address translation: Intuitively, we would imagine that given a cache, if we have a buffer whose size matches the cache size, then accessing each element in the buffer allows us to fully occupy every slot in the cache. However, this may not always be the case, due to virtual to physical address translation. Note that on our machine, the cache mapping is a function of physical address, while the software uses virtual address. Let’s consider a toy example where a 8KB directly-mapped cache which can hold two 4K pages. If we have a two-page-size buffer, after virtual address translation, we can end up with three posibilities: 1) the buffer covers the whole cache; 2) both pages map to the top half of the cache; and 3) both pages map to the bottom half of the cache. In this case, how can we reliably evict data from a certain cache level without the control of the address translation procedure? The common trick is to just use a buffer that is bigger than the cache itself – between 1.5x or even 4x of the cache size. Even though the eviction might still not be guaranteed, its likelihood is high enough. | . 1-3 Discussion Question . After completing your code, generate the histogram pdf file and include it in the lab report. 1-4 Discussion Question . Based on the generated histogram, report two thresholds, one to distinguish between L2 and L3 latency and the other to distinguish between L3 and DRAM latency. Submission and Grading . You will need to submit the code Part1-Timing/main.c to your assigned GitHub repository. Your code should be able to reproduce the histogram you submitted. You can determine whether your implementation is correct by check the description in expected outcome. Due to noise, we will run your code multiple times (5 times) and grade based on the best results. You should feel comfortable to submit your code as long as it can generate the expected results most of the time. ",
    "url": "/2025/labs/cache.html#part-1-gathering-information-15",
    "relUrl": "/labs/cache.html#part-1-gathering-information-15"
  },"4": {
    "doc": "Cache Attacks",
    "title": "Part 2: Capture the Flag with Flush+Reload (25%)",
    "content": "From now on, we are entering attack time. In this part of the lab, you will be attempting to extract secrets from a victim program. You will get a taste of solving a Capture-the-Flag (CTF) puzzle. The future labs will follow a similar pattern. Get to Know the Victim . We provide you with a victim program in Part2-FlushReload/victim, whose pseudocode is listed below. The victim program uses mmap to map a file into its own virtual address space to create a buffer. It then generates a random integer as the flag and uses the flag to index into the buffer. Your task is to learn the flag value by monitoring the victim’s memory accesses using a Flush+Reload attack. // Allocate a large memory buffer char *buf = get_buffer(); // Set the flag to random integer in the range [0, 1024) int flag = random(0, 1024); printf(flag); // Main loop while (true) { value = load(buf + flag * 128); } . The Attack Setup and Your Plan . We have set up the attack framework that enables your attacker program to share a memory region with the victim. It uses a technique called memory-mapped file, where two virtual addresses (one from your program’s address space and the other from the victim’s address space) are mapped to a same physical address, which contains a copy of a file on the hard drive. You can use the figure below to understand what is happening under the hood. The buf in the victim program and the buf in the attacker program point to the same physical address . Your attack should implement standard Flush+Reload. We are providing you with the attack skeleton and several practical tips. | Flush: Flush all the cache lines that might be accessed by the victim to DRAM using clflush. Be careful with the aforementioned cache line granularity issue. Note that cache size != integer size. | Wait: Wait a few hundred cycles for the victim to perform the flag-dependent memory load operations. Don’t use the system-provided sleep function to do this – similar to printf, this function will trigger a system call, potentially destroying cache states. | Reload: Re-access all the cache lines in the Flush step and measure the access latency to each of them. Use the threshold derived from Part 1 to decode the flag value. | . 2-1 Exercise . Complete the code in Part2-FlushReload/attacker.c to successfully extract the secret values from Part2-FlushReload/victim. To test your attack, you should first compile your code using make and generate a file for the shared buffer using python3 gen_file.py. Then use tmux, screen, or simply two SSH connections, and run make run_victim in one terminal and make run_attacker in another terminal. Make sure you are NOT executing ./victim or ./attacker directly because they will not launch the binary on your assigned cores. If you have problems running the victim binary, you may need to run chmod +x victim. Hardware Prefetchers . Modern processors can predict future memory accesses and prefetch data into the cache before it is used. Hardware prefetching is an effective performance optimization technique that is widely deployed in real-world processors. This feature can confuse your attack code. For example, regardless of what the flag value is, some Flush+Reload attack implementation may consistently observe a cache miss for the first reload operation, and cache hits for the rest of the reload operations, because the first load miss triggers hardware prefetching for the later addresses. Usually, the hardware prefetcher makes address prediction based on simple patterns, such as a linear, fixed-stride access pattern within a page. Therefore, you can bypass the prefetching effects by introducing randomness to your address access pattern. The prefethers are enabled on the lab machines. Make sure you have avoided aforementioned simple access patterns in your code. 2-2 Discussion Question . In the victim’s pseudocode above, the victim attempts to load the data indexed by flag into the value variable. How can you change the victim’s code to load the desired data without leaking the flag to the attacker? . Submission and Grading . You will need to submit the code Part2-FlushReload/attack.c to your assigned GitHub repository. Your code should be able to reliably capture the flag. Due to system noise, we will grade this part by executing your code multiple times. Full credit will be awarded if your code works at least 4 out of 5 runs. ",
    "url": "/2025/labs/cache.html#part-2-capture-the-flag-with-flushreload-25",
    "relUrl": "/labs/cache.html#part-2-capture-the-flag-with-flushreload-25"
  },"5": {
    "doc": "Cache Attacks",
    "title": "Part 3: Capture the Flag with Prime+Probe (35%)",
    "content": "We will now solve a more challenging CTF puzzle, leaking the flag using a Prime+Probe attack. In this setup, the attacker and the victim no longer share memory, and thus Flush+Reload will not work. Instead, to make the attack work, you need to carefully manipulate cache states and trigger cache set-conflicts. Get to Know the Victim . We have created several victim binaries, victim-N, whose pseudocode is listed below. Each victim program generates a random number as the flag. Then it finds a collection of addresses that all map to the same L2 cache set whose set index matches this flag value. The value N denotes the number of cache lines being accessed by the victim, reflecting the strength of the side-channel signal. Intuitively, using a smaller N means the victim accesses fewer ways in a given cache set, and the generated side-channel signal is weaker, making attacks more difficult. We have provided the binary for victim-[16,4], where victim-16 accesses the full cache set and is easier to attack. // Allocate a large memory buffer char *buf = get_buffer(); // Set flag to random integer in the // range [0, NUM_L2_CACHE_SETS) int flag = random(0, NUM_L2_CACHE_SETS); printf(flag); // Find N addresses in buf that all map to the cache set // with an index of flag to create a partial eviction set char *eviction_set[N]; get_partial_eviction_set(eviction_set, flag); // Main loop while (true) { for (int i = 0; i &lt; N; i++) { // Access the eviction address (*(eviction_set[i]))++; } } . Before Attacking: Cache Addressing . Given the victim’s behavior described above, you will build a Prime+Probe covert channel targeting the L2 cache. Similar to previous parts, the addresses you are dealing with in your C code are virtual addresses while physical addresses (which you will not have access to within your code) are used when indexing into caches. This fact can be more problematic in this part because you might need to do more careful calculation on the addresses. For a review of virtual memory and address translation, please refer 6.191’s (6.004’s) lectures on Virtual Memory 1 and Virtual Memory 2. It is very tempting to “fudge” the numbers in this lab (e.g., hypertuning various parameters to make incremental changes to your attack’s performance). While this approach may work, we really don’t recommend this approach. Instead, take the time to sit down and calculate all the cache parameters before you move forward may save you more time. Think about the following questions: How many bits are part of the tag in a virtual address? The set index? The offset (within a cache line)? How is this level of the cache indexed (virtually or physically indexed?) Which bits are shared between virtual and physical addresses for both kinds of pages (regular and huge)? You should know the answers to all of these before you start coding! . Addresses look like this to the cache: . And look like this to the paging hierarchy: . You should know what each of these fields does, and how large they are at each level of the cache on the lab machine. 3-1 Discussion Question . Given a 64-bit virtual address, fill in the table below. In the last row, when we say an address bit is fully under the attacker’s control, we mean the address bit is not changed during virtual to physical address translation. |   | Using 4KB page | Using 2MB page | . | Which bits are page offset? |   |   | . | Which bits are used as page number? |   |   | . | Which bits are L2 set index? |   |   | . | Which bits of the L2 set index are fully under your control? |   |   | . Using Hugepage . The default page size used by most operating systems is 4K bytes. Linux supports Huge pages, allowing programs to allocate 2 MB of contiguous physical memory, ensuring 221 bytes of consecutive physical addresses. You can use the mmap system call as follows to get a buffer using 2MB pages. You can use the command man mmap to understand the semantics for each argument used by this function. void *buf= mmap(NULL, BUFF_SIZE, PROT_READ | PROT_WRITE, MAP_POPULATE | MAP_ANONYMOUS | MAP_PRIVATE | MAP_HUGETLB, -1, 0); if (buf == (void*) - 1) { perror(\"mmap() error\\n\"); exit(EXIT_FAILURE); } *((char *)buf) = 1; // dummy write to trigger page allocation . Besides, you can see if your huge page is being allocated or not by watching the status of /proc/meminfo. Namely, if you run cat /proc/meminfo | grep HugePages_, you should see the number of HugePages_Free decrease by 1 when your code is using one. Implementing the Attack: Prime+Probe . We outline the attack procedure below and provide a few tips. The most important rule is, do not try to implement everything then test. Modern processors often contain optimizations that make them behave differently from the simplified architectures taught in class. This lab requires experimentation to find working approaches and values. You should not expect your solution to work on the first attempt, so be sure to incrementally build up your solution and verify that each step is working before proceeding. | Eviction addresses collection: You need to find a group of eviction addresses for each cache set, so that when these eviction addresses are accessed, they can fully occupy a given cache set. This step requires a clear understanding of the cache addressing scheme. We highly suggest you calculate twice, code once. Trust us, sitting down to think through cache addressing before coding will save you time. | Prime: For each cache set, access its corresponding eviction addresses to place these addresses in the cache and fully occupy the cache set. Again, be careful with the mismatch of the size of an integer and a cache line. Repeatedly accessing the same cache line will only bring one line into the cache, far from being able to monitor the whole cache set. | Wait: Similar to the Flush+Reload attack, wait for a few hundred cycles. Do not use system call functions, such as sleep. | Probe: For each cache set, re-access the eviction addresses for each cache set and measure their access latency. You can use simple statistic analysis (e.g., median, average, maximum, or median/average/max after removing outliers) to decode the flag. | . 3-2 Exercise . Complete the code in attacker.c to successfully extract the secret values from victim-[16,4]. Compile your code using make. Then use tmux, screen, or simply two SSH connections, and run make run_victim-N in one terminal and make run_attacker in another terminal. If you have problems running the victim binaries, you may need to run chmod +x victim-N. Practical Coding Tips . If the receiver needs to measure the latency of multiple memory accesses, you should pay attention to the following features that can introduce substantial noise to your communication channel. | Randomizing the access pattern during probe: Similar to the Flush+Reload attack, accessing addresses with a fixed-stride pattern can trigger hardware prefetching and introduce confusing measurement results. The problem is that you do not know when you observe a cache hit, the line was always located inside the cache or it was brought into the cache by the prefetcher. Please avoid simple access patterns in your code. | Probe in the reverse direction: While least recently used (LRU) is the most common example of a cache replacement policy, practical processor implementations often use much more complex policies. You may need to experiment a bit to roughly figure out how eviction and measurement works on your processor. With Prime+Probe attacks, it is common to encounter cache-thrashing or self-conflicts, a situation in which the attacker primes the cache set and evicts their own data with subsequent accesses while probing. For example, consider a 4-way cache using LRU, if we access four pieces of data in the order of A, B, C, D. Here, A will be the oldest data and D will be the youngest. Assume the system has noise where a random application touches a line called X in this set, evicting A out of cache. Now we have B, C, D, X, where B is the oldest and X is the youngest. Think about what if we perform the probe operation and re-accessing A-D in the same order as we prime them, what will happen? We will trigger the cache-thrashing effects where accessing A will evict B, and the access to B will evict C. As this pattern continues, we end up with 4 cache misses. As you see, a small amount of noise makes us lose the capability of monitoring the given cache set. Prior work has studied better access patterns to bypassing the cache-thrashing effects. The idea is to access the eviction addresses in one direction in Prime and in the reverse direction in Probe. Following the example above, we will need to access the four addresses in the order of D, C, B, A during probe. More studies on cache attack access ordering have been discussed in Tromer et al. | Keep data on the stack: This is more a rule of thumb than a hard “law” of microarchitectural attacks. One of our prior TAs, Joseph Ravi, found that keeping as much of your measured data (i.e., the latencies of memory accesses) on the stack (instead of the heap) as you can reduces noise. Note that, writing your measured data to an array, this operation itself, can introduce noise to our attack. Since stack anyway is frequently accessed, putting the measured data array onto stack may introduce less interference. | . Submission and Grading . You need to submit the code Part3-PrimeProbe/attack.c to your assigned GitHub repository. We give credits if your code can reliably capture the flag in the following victims in 2 minutes, and when we say reliably, we mean your attack works at least 4 out of 5 runs. Your code needs to first work reliably targeting victim-16 to get 25% of the credits and then victim-4 to get the remaining 75%. As always, do not forget to include answers to the discussion questions in your lab report and submit the report to gradescope. ",
    "url": "/2025/labs/cache.html#part-3-capture-the-flag-with-primeprobe-35",
    "relUrl": "/labs/cache.html#part-3-capture-the-flag-with-primeprobe-35"
  },"6": {
    "doc": "Cache Attacks",
    "title": "Part 4: Dead Drop – An Evil Chat Client (25%)",
    "content": "If you find leaking an integer is not exciting enough, you can level it up to build a covert channel to send and receive arbitrary messages, like an evil chat client that can stealthily communicate without being monitored by privileged software, such as the OS. In this part, you can decide to build a chat client using either Prime+Probe or even some other fancy side channels. There are only very few requirements. | The sender and receiver must be different processes. | The sender and receiver may only use syscalls and the functions accessible from the provided util.h except for system() and clflush(). There is no way to set up a shared writable address space between the sender and receiver, nor is there a way to call any obviously-useful-for-chat functions such as Unix sockets. | If you would like to use some convenience code that stays within the spirit of the lab, please contact the course staff. Obviously, you may not use pre-packaged code from online for building covert channels (e.g., mastik). | . Expected Behaviour . The Dead Drop client should behave in the following way. Using tmux, screen, or simply two SSH connections, we can have two different terminals running on the same machine and run the following commands: . Terminal B: $ make run_receiver // you start the receiver process in a terminal Terminal B: Please press enter. // the receiver prompts you to press enter to start listening for messages Terminal A: $ make run_sender // you start the sender in another terminal Terminal A: Please type a message. Terminal B: $ // you press Enter in the receiver's terminal Terminal B: Receiver now listening. Terminal A: $ Hello, World! // you type a message and hit enter in the sender's terminal Terminal B: Hello, World! // receiver should generate the same message as you entered on the sender's side . Note that you should support messages containing arbitrary number of characters. For example, the message “Hello, World!” above contains 13 characters and is typed by user together. Then all 13 characters appear on the receiver side. To achieve this, your sender needs to signal the receiver that “the next character is coming” in some way. Partial credits will be awarded for solutions which only support a fixed number of characters in a message. Submission and Grading . You need to submit your code to your assigned GitHub repository. You will then demonstrate your attack in person with a course staff during office hours or in a scheduled meeting. You code needs to first successfully send and receive the “Hello, World!” message to get 80% of the credits and then messages with arbitrary length and contents to get the remaining 20%. We do not accept code that directly prints the “Hello, World!” message in the receiver. Acknowledgments . Contributors: Miles Dai, Weon Taek Na, Joseph Ravichandran, Mengjia Yan, Peter Deutsch, Shixin Song. The original Dead Drop lab (Part 4 of this lab) was developed by Christopher Fletcher for CS 598CLF at UIUC. The starting code and lab handout are both heavily adapted from his work. ",
    "url": "/2025/labs/cache.html#part-4-dead-drop--an-evil-chat-client-25",
    "relUrl": "/labs/cache.html#part-4-dead-drop--an-evil-chat-client-25"
  },"7": {
    "doc": "Cache Attacks",
    "title": "Cache Attacks",
    "content": " ",
    "url": "/2025/labs/cache.html",
    "relUrl": "/labs/cache.html"
  },"8": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": "All content on this website, including the calendar, is subject to change. | Monday | Tuesday | Wednesday | Thursday | Friday | . | Feb 3LectureOverview | Feb 4 | Feb 5LectureSide Channel Overview | Feb 6 | Feb 7 | . | Feb 10RecitationCTF of C Programming | Feb 11Lab 0 Due | Feb 12LectureDeep Dive of Cache Side Channels | Feb 13 | Feb 14 | . | Feb 17No ClassPresident’s Day | Feb 18RecitationCache AttackLab 1 Due | Feb 19LectureTransient Execution Side Channels | Feb 20 | Feb 21 | . | Feb 24LectureSoftware-Hardware Contract | Feb 25 | Feb 26LectureSide-channel Mitigations (by Yuheng Yang) | Feb 27Lab 2 Mid-checkpoint | Feb 28 | . | Mar 3LecturePhysical Attacks (by Joseph Ravichandran) | Mar 4 | Mar 5RecitationCTF of Physical Attacks | Mar 6 | Mar 7 | . | Mar 10DiscussionRecent Microarchitecture Attacks | Mar 11Lab 2 Due | Mar 12LectureHardware Security Module (HSM) | Mar 13 | Mar 14 | . | Mar 17TalkIoT &amp; embedded security (Prof. Yan Long) | Mar 18 | Mar 19LectureRowhammer Attacks | Mar 20Lab 3 Due | Mar 21 | . | Mar 24No ClassSpring Break | Mar 25No ClassSpring Break | Mar 26No ClassSpring Break | Mar 27No ClassSpring Break | Mar 28No ClassSpring Break | . | Mar 31LectureRowhammer Mitigation + Reliability Solutions (by Peter Deutsch) | Apr 1 | Apr 2DiscussionMore Physical Attacks | Apr 3 | Apr 4 | . | Apr 7LectureHardware Support for Software Security | Apr 8 | Apr 9LectureFuzzing and Bug Finding | Apr 10Lab 4 Due | Apr 11 | . | Apr 14RecitationRISC-V System Programming | Apr 15 | Apr 16TalkTBD | Apr 17Lab 5 Due | Apr 18 | . | Apr 21No ClassPatriot’s Day | Apr 22Drop Date | Apr 23LectureFormal Verification for Hardware Security | Apr 24 | Apr 25 | . | Apr 28RecitationFormal Verification Toolchain | Apr 29Lab 6.A Mid-checkpoint | Apr 30DiscussionHardware Support for Software Safety | May 1 | May 2 | . | May 5LectureTrusted Execution Environment (TEE) | May 6Lab 6.A Due | May 7DiscussionFuzzing and Formal Verification | May 8 | May 9 | . | May 12No ClassOffice Hour at 32-G7 Lobby | May 13Lab 6.B Due | May 14 | May 15 | May 16 | . ",
    "url": "/2025/calendar.html",
    "relUrl": "/calendar.html"
  },"9": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": " ",
    "url": "/2025/calendar.html",
    "relUrl": "/calendar.html"
  },"10": {
    "doc": "C Crash Course",
    "title": "C Crash Course Lab",
    "content": "Due Date: Feb 11; Last Updated Date: Jan 22 . ",
    "url": "/2025/labs/ccc.html#c-crash-course-lab",
    "relUrl": "/labs/ccc.html#c-crash-course-lab"
  },"11": {
    "doc": "C Crash Course",
    "title": "Table of Contents",
    "content": ". | Introduction . | Setup | . | Common types of Bugs . | Memory Safety Bugs . | Spatial Memory Safety Bugs | Temporal Memory Safety Bugs | Memory Leaks | Uninitialized Types | Errorneous Return Values | Integer Overflows | Undefined Behavior | Race Conditions | . | . | Debugging Tips: . | Print Debugging | Sanitizer Debugging | Using an Actual Debugger | . | The Lab . | The Basics | Example Bug | Some hints | Additional Tester Features | Grading | Submission | . | Acknolwedgements | . ",
    "url": "/2025/labs/ccc.html#table-of-contents",
    "relUrl": "/labs/ccc.html#table-of-contents"
  },"12": {
    "doc": "C Crash Course",
    "title": "Lab Details",
    "content": "Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . This lab is done on the Unicorn server - you will receive an email with login instructions. This can also be solved locally through the provided Dockerfile. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. ",
    "url": "/2025/labs/ccc.html#lab-details",
    "relUrl": "/labs/ccc.html#lab-details"
  },"13": {
    "doc": "C Crash Course",
    "title": "Introduction",
    "content": "For the labs in this class, you will have to write a lot of C. This includes plenty of debugging too! Every year, we encounter many students who come to office hours due to a lack of understanding of basic C, so we decided to make this lab as a crash course. In this lab, you will help fix the bugs of a basic note taking library. We will run it through a series of test cases to catch for bugs and functionality problems. While we don’t expect the lab to be trivial for most people, if you find yourself struggling significantly to get through this lab, you should consider if this course is fit for you. And please do not use LLMs to analyze shd-lib.c - later labs won’t be solveable through them. LLMs are perfectly fine though if you are rusty on C and need a crash course. Setup . Please do the lab on the provided machines once available. This is important, because I have setup the tests to layout the process heap in a specific way to maximize the chances of catching specific bugs (and we will grade in this same environment)! For those who start before the machines are provisioned, feel free to use the provided docker-run.sh script and Dockerfile. You can also solve this lab locally (especially if you are on Ubuntu 22.04), but please do a final check on the provided machines! . First, clone the lab from git. You can now modify shd-lib.c (and only this, we will ignore all other diffs during submission) and then run the tester binary. Note that your modifications only rebuild the library, which the tester uses. We do not provide the source for the tester or any debugging symbols on purpose - feel free to reverse engineer it, but it’s much pretty trivial to deduce the test cases from the library anyways. If you can reconstruct the tester binary to a reasonable degree and demonstrate so through a report with readable pseudo-C, we’ll give you full credit for this lab automatically. Use make libshd-lib.so to rebuild the library, and then make run to run the tester (or ./tester). You can also run it with SANITIZED=1 make libshd-lib.so to build with ASAN and UBSAN (we will elaborate on this later on). You will need to use make sanitized-run for this version (or ./sanitized_tester), which has specifies the correct libraries to use for sanitizers. Finally, make check is what we will use for grading. There are many bugs that trigger silently (ie. no visible corruption), and we will use Valgrind to catch a subset of those. Feel free to write your own tester binary as well and link it to libshd-lib.so. You can add a Makefile rule and call make &lt;rule_name&gt;. This can be good practice for writing more C! For example: . LDFLAGS = -L. -lshd-lib -Wl,-rpath=. tester: custom.c libshd-lib.so $(CC) $(CFLAGS) custom.c -o tester $(LDFLAGS) . LLMs are really good for writing Makefiles too if you want to do some other setup. Lastly, some tips for using Makefiles. The filenames appearing after a rule name are the dependencies - make re-runs a rule if the file which correlates to a rule name has an earlier modification timestamp than its dependent filenames. make clean has been setup to clean the local build directories, make -B will force a re-make of everything regardless of modification timestamps, and make -j&lt;num&gt; will parallelize the build process with num cores (you shouldn’t need this at all for this lab). ",
    "url": "/2025/labs/ccc.html#introduction",
    "relUrl": "/labs/ccc.html#introduction"
  },"14": {
    "doc": "C Crash Course",
    "title": "Common types of Bugs",
    "content": "C is very prone to bugs. Despite the many existing solutions, C is still the lingua franca of low-level systems programming, and gives you the most precise control over generated machine code. In this lab, you should encounter most of these bugs unless otherwise stated: . Memory Safety Bugs . Spatial Memory Safety Bugs . Unlike most modern languages, C has no runtime bounds checking for array/buffer access. Combined with unchecked pointer arithmetic, one can really reference any offset from an object and potentially achieve arbitrary read or write. These issues are known as spatial memory violations. They can corrupt adjacent objects, stack return addresses, and other elements necessary for correct program execution. Some common bugs that fall under this category are known as OOB (out-of-bound) accesses and buffer overflows. While many of these seem trivial to fix, beware of string related operations. C represents strings as a null-terminated char array, and that final null byte can lead to a lot of off-by-one errors. Temporal Memory Safety Bugs . Unlike garbage-collected languages, memory is manually managed in C. Unlike smarter manual memory management languages like Rust or Ada (and really modern C++ too if you know how to use it correctly), C provides no compile time guarantees to act as guard rails for memory management. Temporal violations often involve de-referencing freed memory, which are known as use-after-frees. This can then lead to corruption within the allocator state or objects that are re-allocated in the same region (this is known as a type confusion bug). Double frees, in which memory is freed twice, will also trigger similar issues. This may seem like a silly issue for one to program, but will happen quite easily as code complexity increases. Memory Leaks . This closely relates to temporal memory safety bugs. Without a garbage collector, there is no runtime object liveness analysis. If you forget to manually free memory, your program will continue to grow in memory size. While perfectly fine for short-lived programs (and probably the correct thing to do for performance), this becomes a major problem for larger programs. Leak enough memory on Linux and you will trigger the OOM-killer, which starts going down your OS’s process list and terminating processes to free up memory. Our usage of Valgrind will specifically catch for this type of bug. Uninitialized Types . There is no default initialization value in C. If you don’t explicitly initialize a variable, its contents will be undefined (usually, the contents come from a previous value at that same location). This can lead to a source of bugs! An extremely common case last year was students not initializing a data array, and ending up confused of how the sum of 0 data points for a certain index resulted in a random large number. Errorneous Return Values . C doesn’t really have a built-in exception system nor does it have the concept of a result/option monad like in Rust or Haskell for error checking. The type system thus causes an errorneous return value to share the same type as a successful return value (C has unions, but those unions have no enforced safety guarantees). A common case for this is in syscall relevant functions such as read - on success, it tells you the number of bytes that are read, but on failure, it returns a specific negative value. Another example more relevant to this lab are functions that return heap-allocated objects. On success, they will return a valid pointer, but on failure, it will return a null pointer. Technically, the address 0x0 can still be a valid address depending on system configuration, which makes null pointers especially problematic in certain scenarios… Tony Hoare calls this his billion dollar mistake. Integer Overflows . If you are familiar with a real programming language, then you already know this. If you come from Python, then pay attention. Integer primitives in real languages are backed by hardware registers, which are limited in size. Eventually, a register will overflow (Ex. adding 1 to 2^63-1 will overflow and bring the value back to 0). You should expect the natural number wrapping behavior for unsigned integers in C, but this overflow becomes undefined behavior for signed integers, which leads to our next point. There are also many other integer related quirks - take this quiz to see how much you know! . Undefined Behavior . This is a very large class of bugs. C lists many different things as undefined behaviors, which basically means the compiler can do whatever it wants, including wiping your whole hard drive, and make any assumptions it wants (usually for the purpose of code optimization). This can lead to very very surprising behavior! Technically many of the previously discussed bugs fall in the category of “undefined behavior.” . Race Conditions . You won’t encounter this in our lab. But this is a problem that plagues every language whenever concurrency and parallelism enters the picture. A subclass of this includes data races, which some strongly typed languages like Rust has solved. ",
    "url": "/2025/labs/ccc.html#common-types-of-bugs",
    "relUrl": "/labs/ccc.html#common-types-of-bugs"
  },"15": {
    "doc": "C Crash Course",
    "title": "Debugging Tips:",
    "content": "There are a few ways to debug in C. Print Debugging . The best way in my opinion is print debugging. Use printf to add print statements wherever you need them. You can easily deduce all the test cases as well with this technique. Note that our tester binary includes the following initial call: . setbuf(stdin, NULL); setbuf(stdout, NULL); setbuf(stderr, NULL); . Standard library level IO functions often buffer input - you might miss a print statement if you don’t end the text with a newline as the default is line-buffering (and will also affect the heap layout). These setbuf calls disable bufferring. C print functions rely on format specifiers, and you can learn all about them https://man7.org/linux/man-pages/man3/fprintf.3.html. Generally, you only need %d for uint32_t (I highly recommend that everyone use the bitwidth typed integers in C from stdint.h instead of the default integer types in C), %lld for uint64_t, %x for uint32_t in unsigned hex, %llx for uint64_t in unsigned hex, %p for pointers, %c for chars, and %s for strings. For example, if foo is a pointer to some struct, bar is an uint32_t, and foobar is a string, you would do this: . printf(\"foo: %p bar: %x foobar: %s\", foo, bar, foobar); . Do not ever directly print a non-compile time constant string as the first argument in printf ever in C code. Doing so will get your codebase compromised thanks to a specifier known as %n that allows for arbitrary write into memory. Sanitizer Debugging . Recall ASAN and UBSAN from earlier. These are helpful tools that instrument your code to help catch most memory safety and undefined behavior bugs during runtime. You run the instrumented version and whenever a violation is detected, you receive a report with a backtrace. For example, the starter code will trigger the following backtrace one of the first test cases./sanitized_tester ------------------------------------------------------------ Running BUG_CHECK_0 Test, notebook length: 10 ------------------------------------------------------------ read_page AddressSanitizer:DEADLYSIGNAL ================================================================= ==357005==ERROR: AddressSanitizer: SEGV on unknown address 0x607000013980 (pc 0x7f7d7371584e bp 0x7ffd21a66fc0 sp 0x7ffd21a66fa0 T0) ==357005==The signal is caused by a READ memory access. #0 0x7f7d7371584e in read_page /shd-lib.c:25 #1 0x5e37b6534bd9 (/sanitized_tester+0xaabd9) #2 0x5e37b6554c54 (/sanitized_tester+0xcac54) #3 0x5e37b6529301 (/sanitized_tester+0x9f301) #4 0x5e37b65133b7 (/sanitized_tester+0x893b7) #5 0x7f7d71c29d8f in __libc_start_call_main ../sysdeps/nptl/libc_start_call_main.h:58 #6 0x7f7d71c29e3f in __libc_start_main_impl ../csu/libc-start.c:392 #7 0x5e37b6513944 (/sanitized_tester+0x89944) AddressSanitizer can not provide additional info. SUMMARY: AddressSanitizer: SEGV /shd-lib.c:25 in read_page ==357005==ABORTING . You can catch a lot of bugs just with this technique. Using an Actual Debugger . This should be your last resort, but can be useful for pinpointing some hard to catch bugs. The debugger I recommend is GDB with GEF extensions. Vanilla GDB looks ugly, isn’t fun to use, and defaults to AT&amp;T assembly syntax. There are many GDB guides out there, but these are what I find useful (though GEF already automatically shows a lot of the information these commands can reveal). | bt: for dumping a stack backtrace | p $&lt;var&gt;: display the value of a variable (which can just be a register name or an address). You can also typecase the var in C syntax to get a pretty-print, but that is dependent on whether there is sufficient DWARF debug information. | disas &lt;address&gt;: disassembles the current function, or starting from an address if specified. | x/&lt;NUM&gt;&lt;specifier&gt;x &lt;address&gt;: Shows NUM specifier sized elements in hex starting from address. Specifiers include g for giant word (8 bytes), w for word (4 bytes), h for half-word (2 bytes), or b for byte. If you replace the x after the specifier with an i, you can get a disassembly dump as well. | b sym/b address: set a breakpoint at an address. You can also specify a conditional expression for conditional breakpoints. | watch: watchpoints are like breakpoints, but for value changes in the program. I really doubt you’ll ever need it in this class, but a useful tool to have | c: continue program execution | r: start program execution | s/n: step and next. Step goes to the next source line, entering function calls, while next goes to the next source line, skipping function calls. There are many different variations of this, so take a look here. One variation worth mentioning are the stepi and nexti variants, which operate at the instruction granularity. | search-pattern: a GEF specific extension that is a life-saver. This allows you to search for arbitrary memory patterns at arbitrary address ranges. | . ",
    "url": "/2025/labs/ccc.html#debugging-tips",
    "relUrl": "/labs/ccc.html#debugging-tips"
  },"16": {
    "doc": "C Crash Course",
    "title": "The Lab",
    "content": "The goal of this lab is to fix the bugs - passing the tester checks should satisfy most of that. The Basics . Refer very carefully to the comments in shd-lib.h for the spec. One thing to realize about the struct definitions is the array declaration in page_t: . typedef struct { size_t len; char content[]; } page_t; . Usually, variable length arrays are not allowed in structs, except when it is the last field. This is a very common pattern in networking or IPC code. You can allocate these types of elastic structs with the following pattern: malloc(sizeof(elastic_type) + additional_size). In general, this library provides notebook objects with a fixed amount of pages, which users can read, write, erase, grow, and append to. Example Bug . One really simple bug that you should catch immediately is the lack of bounds checking in all the notebook relevant operations. Users have to specify a page_nr for most of them, yet there are no checks to see whether the page_nr is even possible for this notebook’s pages array. Some hints . | As mentioned earlier, the null byte in C strings can be really finnicky, especially when performing operations on them. | The first 6 bugs we discussed earlier all appear here (and technically the 7th, because all those bugs lead to undefined behavior) | I talked about reading the spec for shd-lib.h earlier, but what about malloc, free, and realloc | Remember the base size of flexible structs. | One really tricky bug comes directly from a real world bug. Look into the root cause of CVE-2022-0185 for the Linux kernel. Don’t worry, all you need is basic C knowledge and it’s a one line fix! | . Additional Tester Features . Since certain bugs more easily manifest themselves from a simpler heap state in these short test cases (before many deallocations occur), you can manually run the ./tester binary with a list of names of certain BUG_CHECKS to run through. For example: ./tester BUG_CHECK_3 BUG_CHECK_6 BUG_CHECK_9. 1-1 Exercise . Fix all the bugs in shd-lib.c so that the test cases can pass! . 1-2 Discussion Question . Write about 5 bugs that you found in this lab. A single sentence for each will suffice. Grading . The programming component makes up 90% of the points in this lab. Each test case is worth the same (with the final valgrind test being considered a single test case). Our grader does NOT take into consideration of a passing test case that comes after a crashing test case. The discussion makes up 10% of the points in this lab. Submission . Push your code to the Github classroom, and submit your discussion responses to Gradescope. ",
    "url": "/2025/labs/ccc.html#the-lab",
    "relUrl": "/labs/ccc.html#the-lab"
  },"17": {
    "doc": "C Crash Course",
    "title": "Acknolwedgements",
    "content": "Contributors: William Liu, Shixin Song, Mengjia Yan . ",
    "url": "/2025/labs/ccc.html#acknolwedgements",
    "relUrl": "/labs/ccc.html#acknolwedgements"
  },"18": {
    "doc": "C Crash Course",
    "title": "C Crash Course",
    "content": " ",
    "url": "/2025/labs/ccc.html",
    "relUrl": "/labs/ccc.html"
  },"19": {
    "doc": "Website Fingerprinting",
    "title": "Website Fingerprinting Lab",
    "content": "Due Date: Feb 18; Last Updated Date: Jan 22 . ",
    "url": "/2025/labs/fingerprinting.html#website-fingerprinting-lab",
    "relUrl": "/labs/fingerprinting.html#website-fingerprinting-lab"
  },"20": {
    "doc": "Website Fingerprinting",
    "title": "Table of Contents",
    "content": ". | Introduction | Part 1: Warm-up (20%) . | Hello World (Optional) | Timing Measurement | . | Part 2: Side Channel Attacks with JavaScript (60%) . | The Sweep Counting Attack | Part 2.1: Cache Trace Collection + Processing | Part 2.2: Automated Attacks with Machine Learning | . | Part 3: Root Cause Analysis (20%) | Takeaways | Contributors | . ",
    "url": "/2025/labs/fingerprinting.html#table-of-contents",
    "relUrl": "/labs/fingerprinting.html#table-of-contents"
  },"21": {
    "doc": "Website Fingerprinting",
    "title": "Lab Details",
    "content": "Collaboration Policy . Our full Academic Honesty policy can be found on the Course Information page of our website. As a reminder, all 6.5950/6.5951 labs should be completed individually. You may discuss the lab at a high level with a classmate, but you may not work on code together or share any of your code. Getting Started . This lab is done on your own computer, and should be (micro)architecture agnostic. If you don’t have a device to use, please reach out to the TA. You will complete this lab primarily in Python and JavaScript. We are using git for all the labs – instructions for setting up the git repository can be found on the labs page. In addition to submitting code, you are required to submit a PDF lab report containing your answers to Discussion Questions to gradescope. We provide a markdown template in the starter code (report.md). ",
    "url": "/2025/labs/fingerprinting.html#lab-details",
    "relUrl": "/labs/fingerprinting.html#lab-details"
  },"22": {
    "doc": "Website Fingerprinting",
    "title": "Introduction",
    "content": "In this lab, you will complete the following tasks: . | Launch an end-to-end side-channel attack to conduct website fingerprinting. | Try to understand the root cause of this attack. | . What is website fingerprinting? . In a website fingerprinting attack, an attacker tries to distinguish which website a victim has accessed on their machine. Website fingerprinting attacks can allow an attacker to gather a lot of user information, such as political views, religious beliefs, and sexual orientation. There exist many variants of website fingerprinting attacks, which we can classify into two categories (based on the resources that the attacker can access): on-path attacks and co-located attacks. An on-path attacker executes on a different machine from the victim. The attacker observes all network packets sent and received by the victim’s machine and infers the website based on the timing and size of the observed network packets. In contrast, a co-located attacker executes on the same machine and shares microarchitectural resources with the victim, including caches, DRAM, and GPUs. In the case of a low-privileged attacker, this co-location can be achieved by running attacker-controlled JavaScript code in a different browser tab. We focus on co-located attacks in this lab. Example of co-located attack setup (source) . What is the plan? . You will implement a variant of cache-occupancy side-channel attacks, called Sweep Counting Attack. This attack was originally described in the following two papers. Reading these two papers is not required to complete the lab, however they discuss several other attack techniques that you may find inspiring. | Robust Website Fingerprinting Through the Cache Occupancy Channel: Section 4.1, Page 8, Website Memorygrams. | Prime+Probe 1, JavaScript 0: Overcoming Browser-based Side-Channel Defenses: Section 3.1, Page 5, Sweep Counting. | . You will demonstrate the attacks mounted from inside a web browser (a restricted execution environment). A browser usually cannot access fine-grained timers, cache-flushing instructions, or manipulate low-level memory. As such, after you complete this lab, you will hopefully see how versatile side channels are. Our plan of attack involves 1) writing JavaScript code to collect side-channel traces; and 2) using machine-learning techniques to analyze the traces we collect. Knowledge of the internal machine-learning techniques and mechanisms is not required. Instead, the goal is to allow you to use ML as a black-box tool. The attack you’ll develop in this lab should work in any web browser, including Chrome, Firefox, Safari, and even the Tor browser. Discussion Question (Optional) . Report your browser version, CPU type, cache size, RAM amount, and OS. We use this information to learn about the attack’s behavior on different machines. ",
    "url": "/2025/labs/fingerprinting.html#introduction",
    "relUrl": "/labs/fingerprinting.html#introduction"
  },"23": {
    "doc": "Website Fingerprinting",
    "title": "Part 1: Warm-up (20%)",
    "content": "In this part, you will familiarize yourself with the development environment and determine the timer resolution offered by JavaScript. Code Structure . | warmup.js: A JavaScript file with two functions, measureOneLine and measureNLines, which you will complete. | warmup.html: A webpage that displays the return values of the two functions. | . Hello World (Optional) . As a warm-up exercise, we will guide you through JavaScript development by writing a simple Hello World program. If you’re familiar with JavaScript, feel free to skip to Timing Measurement. Otherwise, here we provide a brief overview of JavaScript and the developer tools you’ll need for this lab. By including &lt;script src=\"warmup.js\"&gt;&lt;/script&gt; on line 31 of warmup.html, your browser downloads, runs, and executes the script’s contents immediately upon loading warmup.html. You can test this by adding a simple print function like console.log(\"Hello World!\"). You can then view the console by right-clicking the page, selecting Inspect (Cmd-Opt-I on MacOS or F12 on Windows/Linux), and then selecting Console. In Safari, you may need to unlock inspect mode with Safari &gt; Preferences &gt; Advanced &gt; Show Develop Menu. You can use console.log to debug your JavaScript code. JavaScript’s basic syntax is fairly similar to other languages you might be familiar with, such as C or Java. If you need to review JavaScript’s syntax while completing this lab, feel free to refer to various online resources. Exercise (Optional) . Add a console.log statement with a message of your choice, anywhere in warmup.js. Then, open warmup.html in your web browser and check the console to ensure that your message is displayed. Timing Measurement . Before we can execute a timing side-channel attack, we need to determine the quality (i.e., resolution) of the timer. The JavaScript’s timer (in milliseconds) can be accessed via the performance.now() API. This API yields different resolutions depending on the browser – the resolution is 0.1 ms in Chrome 92, and 1ms in Firefox 91. In warmup.js we provide measureOneLine(), an example of how we can measure the access latency of a single memory access using performance.now(). You should see the following output when you open warmup.html in a browser (you may occasionally see some non-zero entries). Website Fingerprinting Lab Warmup 1 Cache Line: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] N Cache Lines: [] . Your first task is to determine the timing resolution of performance.now() by measuring the latency of accessing multiple cache lines. Report the observed value for accessing N cache lines, where N ranges from 1 to 10,000,000. Feel free to access the memory in sequential order, as we are trying to get a rough idea about the timing resolution. You can ignore any potential effects of hardware prefetching. Since you may not get consistent results each time due to system noise, perform the measurement 10 times and report the median access latency. A cache line != A single element in an array . A cache line is different from an element in an array because they have different sizes. The cache line size of your machine is likely 64 or 128 Bytes. If you are not sure, you can use getconf -a | grep CACHE if you are running Linux or use sysctl -a | grep cachelinesize if you are running MacOS. Once you figure out the cache line size, you will want to access an array with a specified stride to make sure each access targets a different cache line. Generally, if you have an x86_64 processor, your cache line size will be 64 bytes. If you are on an ARM core MAC, your cache line will be 128 bytes. 1-1 Exercise . Complete measureNLines() such that it measures the access time of N cache lines 10 times and pushes each measurement to the end of the result array. These values will be displayed on warmup.html when you refresh the page. 1-2 Discussion Question . Use the values printed on the webpage to find the median access time and report your results as follows. | Feel free to find the median value by hand (you are not required to implement the code to do statistic calculation). | In the case that your browser complains about the buffer size that you request is too large (with an “out-of-memory” error), you can fill in the corresponding entry with “N/A”. | . | Number of Cache Lines | Median Access Latency (ms) | . | 1 |   | . | 10 |   | . | 100 |   | . | 1,000 |   | . | 10,000 |   | . | 100,000 |   | . | 1,000,000 |   | . | 10,000,000 |   | . 1-3 Discussion Question . According to your measurement results, what is the resolution of your performance.now()? In order to measure differences in time with performance.now(), approximately how many cache accesses need to be performed? . Submission and Grading . You need to submit part1/warmup.js to your assigned GitHub repository. You should not modify any other files. ",
    "url": "/2025/labs/fingerprinting.html#part-1-warm-up-20",
    "relUrl": "/labs/fingerprinting.html#part-1-warm-up-20"
  },"24": {
    "doc": "Website Fingerprinting",
    "title": "Part 2: Side Channel Attacks with JavaScript (60%)",
    "content": "The Sweep Counting Attack . In a cache-occupancy attack, the attacker leverages the fact that the attacker and victim share the same cache hierarchy. As such, an attacker can monitor its own cache access latency to estimate how much of the cache is occupied by the victim and infer the victim’s behavior. For example, consider an attacker which accesses each element of a Last Level Cache (LLC) sized buffer prior to the victim’s execution. When the victim subsequently performs a lot of memory accesses, it will evict the attacker’s buffer from the cache, and the attacker will observe a longer latency when it re-accesses the buffer. As such, the attacker’s own memory access time is roughly proportional to the number of cache lines the victim accessed. The sweep counting attack is a variant of these cache-occupancy attacks, particularly suited for the case when the attacker is restricted to using low-resolution timers. The attacker allocates a Last Level Cache (LLC) sized buffer and sequentially accesses each cache line in the buffer (like what you have done in Part 1). We call one round of scanning the buffer “one sweep over the LLC.” Then, the attack works by counting how many sweeps over the cache can fit into a single time window whose length is P ms. P ms is on the order of a few milliseconds, and it is a parameter chosen by you. You will repeatedly perform sweep counting for 5 seconds, so that the counters you gather can form a trace with the length as K, where K = 5000/P. Part 2.1: Cache Trace Collection + Processing . Let’s start with implementing the sweep counting attack to collect cache traces in JavaScript. In this attack, the victim code and attacker code resides in two separate JavaScript environments. They can be within two different browser tabs, or entirely separate web browsers on the same machine. The attacker tab will create two threads: a main thread that handles user interactions (e.g., clicking website buttons) and a worker thread that executes your provided code in the background. Note that the worker thread runs even if the attacker tab is not in the foreground. Setting Up The Web Server . To run the worker thread, modern web browsers require that you load the page from a server (rather than simply opening index.html as a file). To get around this issue, you can develop your code by running a simple web server using the following commands, run from the part2/ folder. Make sure you’re using Python3 for this step (and the rest of the lab). $ cd part2 $ python3 -m http.server Serving HTTP on :: port 8000 (http://[::]:8000/) ... Web browsers typically cache the worker thread upon loading the page, so you will need to change your browser’s settings to load updates you make to worker.js. Follow the instructions here in order to do this. If this doesn’t work for you, you can force a refresh of the service worker by opening your worker script at http://localhost:8000/worker.js, holding down shift while clicking the refresh button in your browser’s toolbar, and manually checking that the file’s contents match what you expect. Trace Collection . Open http://localhost:8000 in your preferred web browser. Pressing Collect Trace will begin a countdown, which you can use to prepare your experiment (i.e., switching to a new window). At the end of the countdown, the worker will trigger record(), which will be written by you in worker.js. The output of this function is displayed as a 1D heatmap for convenience. You can click this button multiple times without refreshing the window in order to collect multiple traces. Clicking Download Traces will allow you to download all of the traces collected in a JSON format. You will implement the sweep counting attack inside the record() function. Feel free to refer to the description of the attack at the beginning of Part 2. If you have difficulty in making the attack work, you can also refer to the pseudocode in There’s Always a Bigger Fish: A Case Study of a Misunderstood Timing Side Channel Figure 2. Trace Processing . You can process these downloaded traces in Python with code such as the following: . import json import numpy as np with open(\"traces.json\", \"r\") as f: # Load contents from file as JSON data data = json.loads(f.read()) # Convert 2D array into Numpy for data processing traces = np.array(data[\"traces\"]) # Labels are only available with the automation script. # Use the line below in part 2.2 onward to access them. # labels = data[\"labels\"] # Example data analysis print(traces.mean()) . Such traces can be used to distinguish different system events. The below image shows three traces that were collected under the following circumstances: . | Do nothing while the trace is collected | Add random system activity, moving the mouse during trace collection | Open nytimes.com in a new window during trace collection | . 2-1 Exercise . Complete the record() function in worker.js. Experiment with different P values and collect traces for the three scenarios above for the best value of P you find. Your traces will not exactly match those in the provided example, but they should be visually distinguishable from one another. 2-2 Discussion Question . Report important parameters used in your attack. For each sweep operation, you access N addresses, and you count the number of sweep operations within a time interval P ms. What values of N and P do you use? How do you choose N? Why do not you choose P to be larger or smaller? . 2-3 Discussion Question . Take screenshots of the three traces generated by your attack code and include them in the lab report. Part 2.2: Automated Attacks with Machine Learning . It is tedious and unreliable to launch the victim website manually. To automate the attack process, we provide an automation script (automate.py) based on the Selenium browser automation framework for you to use. Installing Drivers . To complete this section, you will need to install Flask, Selenium, and SciKit-Learn. Make sure you are using Python 3 and install these modules with python3 -m pip install flask selenium scikit-learn. If you do not want to change your defualt Python environment, you can use Python’s support for Virtual Environment . Selenium should automatically install the latest drivers for the browser(s) you have installed. If you are encountering running Selenium, try manually installing the driver using option 3. Using the Automation Script . You can test the automation script by collecting a few traces while your victim opens different websites using the following commands: . $ python3 automate.py --part 2 --domains google.com,nytimes.com --num_traces_per_domain 4 --out_filename traces.out . Detailed descriptions of the arguments used by the automation script can be found by executing python automate.py --help: . usage: automate.py [-h] [--browser {chrome,firefox,safari}] [--domains DOMAINS] [--num_traces_per_domain NUM_TRACES_PER_DOMAIN] [--trace_length TRACE_LENGTH] --out_filename OUT_FILENAME --part {2,3} optional arguments: -h, --help show this help message and exit --browser {chrome,firefox,safari} Browser to run automation in. --domains DOMAINS Comma-separated list of domain names to collect traces from. Defaults to google.com,youtube.com,baidu.com,facebook.com --num_traces_per_domain NUM_TRACES_PER_DOMAIN Number of traces to collect per domain. --trace_length TRACE_LENGTH The length of each recorded trace, in milliseconds. required arguments: --out_filename OUT_FILENAME Name of the output file to save traces to. --part {2,3} Set to the part of the lab you're working on. We recommend starting with a few traces from google.com and nytimes.com. Google is a lightweight website with mostly static content, while NYTimes is a heavyweight website that loads many assets, making them easy to distinguish. 2-4 Discussion Question . Use the Python code we provided in Part 2.1 to analyze simple statistics (mean, median, etc.) on the traces from google.com and nytimes.com. Report the statistic numbers. Using Machine Learning for Classification . Let’s now design a more advanced attacker. Instead of collecting four traces on two websites, we’re going to collect 20 traces on four different websites. As we’re collecting five-second traces, this will take about 7 minutes to run. Pick four of your favorite websites (school appropriate / G-rated) to classify between, pass them to the domains argument, and leave your computer alone until it’s done (to avoid introducing unnecessary noise to your attack). $ python automate.py --part 2 --domains website1.com,website2.com,website3.com,website4.com --num_traces_per_domain 20 --out_filename traces.out . Once the script has finished, you should divide your traces into a training set with 16 traces from each site, and a testing set with 4 traces from each site. The training set is used to train a machine learning model, and the testing set is used to evaluate its accuracy once training is complete. We recommend using the train_test_split function from the scikit-learn library, with test_size=0.2. Then, train a RandomForestClassifier (or another classification model of your choice from scikit-learn) on your training set. Finally, use your model to predict labels for the testing set, and check your model’s accuracy with scikit-learn’s classification_report function. An example classification report is shown below. precision recall f1-score support https://www.baidu.com 1.00 1.00 1.00 4 https://www.google.com 1.00 1.00 1.00 4 https://www.facebook.com 1.00 0.75 0.86 4 https://www.youtube.com 0.80 1.00 0.89 4 accuracy 0.94 16 macro avg 0.95 0.94 0.94 16 weighted avg 0.95 0.94 0.94 16 . 2-5 Exercise . Complete the eval() function in eval.py. In this function you should: . | Load your traces into memory | Split your data into a training and test set | Train a classification model on your training set | Use your model to predict labels for your test set | Print out your model’s accuracy using classification_report | . Use your eval() implementation to analyze the traces that you collected for four websites and print the classification result. Remember to include the traces part2/traces.out in the Github repo to get full credit for this exercise. Exercise (Optional) . Try different machine learning models to see whether you can improve on the accuracy of your previous scheme. 2-6 Discussion Question . Include your classification results in your report. Submission and Grading . You need to submit the code you changed (mainly part2/worker.js and part2/eval.py)and traces (part2/traces.out) to your GitHub repository. The accuracy (i.e. the accuracy f1-score reported in the classification report) can be affected by the websites you choose as well as your web brower versions. Anything higher than 60% accuracy will recieve full credit. In most cases, you should easily be able to achieve 80% accuracy. If your accuracy is lower than 60%, try some websites with more distinguishable content, or try an older version of the web brower. We observe Chrome 98 or earlier works well for MacOS and Chromium 113 works well for Ubuntu. If you still have trouble, reach out to TAs. ",
    "url": "/2025/labs/fingerprinting.html#part-2-side-channel-attacks-with-javascript-60",
    "relUrl": "/labs/fingerprinting.html#part-2-side-channel-attacks-with-javascript-60"
  },"25": {
    "doc": "Website Fingerprinting",
    "title": "Part 3: Root Cause Analysis (20%)",
    "content": "Machine-learning-assisted side-channel attacks are very powerful as they are able to find correlations across traces and can tolerate medium to heavy amounts of noise. A key challenge with using machine learning, however, is that it doesn’t provide us insight as to why an attack works. Given that JavaScript is a high-level language, we do not have full control or knowledge of the instructions being executed on the processor, nor do we have a good idea of where our signal is actually coming from! . In this part, you will try a slightly modified attack to learn about the pros and cons of ML-driven attacks. So far, we have implemented the sweep counting attack, a variant of the cache-occupancy attack. As the name of the attack suggests, this attack leaks information via cache interference. But what if we remove the cache accesses in the code? Will the attack still work? . 3-1 Exercise . Copy your record() function from part2/worker.js to part3/worker.js and modify record() by removing all memory accesses in your code. After removing the memory accesses, all that will remain in loop body is an add operation for incrementing a counter. Therefore, what you end up doing is counting the number of times you perform the add operation within a time window of length P ms. Then re-collect the traces for the four sites you previously examined and report the accuracy. Remember to include the traces part3/traces.out in the Github repo to get full credit for this exercise. 3-2 Discussion Question . Include your new accuracy results for the modified attack code in your report. 3-3 Discussion Question . Compare your accuracy numbers between Part 2 and 3. Does the accuracy decrease in Part 3? Do you think that our “cache-occupancy” attack actually exploits a cache side channel? If not, take a guess as to possible root causes of the modified attack. Note: Without detailed investigation, you will not be able to verify your answer to this question. We will give full credit as long as the reasoning behind your guess is logical. If you’re curious as to the reasons why, we recommend reading the paper There’s Always a Bigger Fish: A Case Study of a Misunderstood Timing Side Channel. We will also discuss this paper in one of the recitation sessions. Submission and Grading . You need to submit your code (part3/worker.js) and the traces (part3/traces.out) to your GitHub repository. Anything higher than 60% accuracy will recieve full credit. ",
    "url": "/2025/labs/fingerprinting.html#part-3-root-cause-analysis-20",
    "relUrl": "/labs/fingerprinting.html#part-3-root-cause-analysis-20"
  },"26": {
    "doc": "Website Fingerprinting",
    "title": "Takeaways",
    "content": "Congratulations on finishing the website fingerprinting lab. We hope your very first experience with the side-channel attack in this class went well. After completing this lab, it would be valuable to recap and think about what you have learned. As the developers of the lab, we hope that, in addition to giving you a taste of attack engineering, the lab can enlighten you with the following takeaway message: Side channels are versatile in modern systems, and with the help of machine learning techniques, they become easier to pull off. However, finding the root cause of a side channel now presents as a new challenge. ",
    "url": "/2025/labs/fingerprinting.html#takeaways",
    "relUrl": "/labs/fingerprinting.html#takeaways"
  },"27": {
    "doc": "Website Fingerprinting",
    "title": "Contributors",
    "content": "Jack Cook, Mengjia Yan, Joseph Ravichandran and Peter Deutsch. ",
    "url": "/2025/labs/fingerprinting.html#contributors",
    "relUrl": "/labs/fingerprinting.html#contributors"
  },"28": {
    "doc": "Website Fingerprinting",
    "title": "Website Fingerprinting",
    "content": " ",
    "url": "/2025/labs/fingerprinting.html",
    "relUrl": "/labs/fingerprinting.html"
  },"29": {
    "doc": "For Instructors",
    "title": "Looking to use our course materials in your course?",
    "content": "There are two things you won’t want to miss: . | Our lab handouts can be found here. | The lab starter code and deployment instructions can be found here. | . ",
    "url": "/2025/forInstructors.html#looking-to-use-our-course-materials-in-your-course",
    "relUrl": "/forInstructors.html#looking-to-use-our-course-materials-in-your-course"
  },"30": {
    "doc": "For Instructors",
    "title": "Get in touch!",
    "content": "Reach out to our team at hw-sec-lab-dev at mit.edu before using our code in your course. We can provide you the instructor’s solutions, a starter gradebook, and grading scripts. ",
    "url": "/2025/forInstructors.html#get-in-touch",
    "relUrl": "/forInstructors.html#get-in-touch"
  },"31": {
    "doc": "For Instructors",
    "title": "For Instructors",
    "content": " ",
    "url": "/2025/forInstructors.html",
    "relUrl": "/forInstructors.html"
  },"32": {
    "doc": "Home",
    "title": "Secure Hardware Design (Spring 2025)",
    "content": "Learn to attack processors… and learn to defend them! . ",
    "url": "/2025/#secure-hardware-design-spring-2025",
    "relUrl": "/#secure-hardware-design-spring-2025"
  },"33": {
    "doc": "Home",
    "title": "Welcome to 6.5950/6.5951 (previously 6.S983 and 6.888)!",
    "content": "6.5950/6.5951 is a research-oriented course on secure hardware design. 6.5950/6.5951 will help you understand the critical security problems in modern hardware and common limitations of existing security solutions. Through a mix of lectures and paper discussions, we will learn the principles of various attacks and how to design effective hardware mitigations and hardware/software co-design solutions. Previous years’ website . Feel free to post your anonymous feedback here during the semester. ",
    "url": "/2025/#welcome-to-6595065951-previously-6s983-and-6888",
    "relUrl": "/#welcome-to-6595065951-previously-6s983-and-6888"
  },"34": {
    "doc": "Home",
    "title": "Meeting Location and Times",
    "content": "Required Lectures: Mondays and Wednesdays from 1:00pm to 2:30pm in Room E25-111. Note that participation is required at scheduled time; take this course only if you will generally be able to participate! . We will use Piazza for all course-related discussion. ",
    "url": "/2025/#meeting-location-and-times",
    "relUrl": "/#meeting-location-and-times"
  },"35": {
    "doc": "Home",
    "title": "Assignments and Grading",
    "content": "6.5950/6.5951 will have no midterm or final exams. There are three required assignments: . | Lab Assignments (85% for graduate version, 97% for undergraduate version): There will be 8 lab assignments. You will be asked to implement your own attacks that work on real machines (not simulators). You must complete all labs to pass this course. | Lab Check-offs(3%): Over the course of the term, we will randomly select one of your labs for an in-person check-off. During a check-off you will discuss your submission with the TA, describing your implementation, and elaborating on your written answers. | Paper Discussion (12% for graduate version): Each student taking graduate version will be asked to select a topic from the 3 discussion sessions, review relevant materials, write a presentation, and lead the class discussion for that topic. To facilitate a fruitful exchange, all students (taking either graduate or undergraduate versions) are expected to read the papers prior to the session and engage in class discussion. Although we will not be formally tracking attendance, we expect regular attendance and participation. | . Grade distribution follows the following categories: . | A: [90, 100] | B: [80, 90) | C: [70, 80) | F: [0, 65) | . ",
    "url": "/2025/#assignments-and-grading",
    "relUrl": "/#assignments-and-grading"
  },"36": {
    "doc": "Home",
    "title": "Staff",
    "content": "Professor Mengjia Yan Email: mengjia at csail.mit.edu Office: 32-G840 Office Hours (32-G840): Fridays 2:30pm-3:30pm . TA Shixin Song, William Liu, Mario Mrowka, Selena Qiao Email: shd-staff at mit.edu Office: 32-G786 Office Hours (32-G7 Lobby): TBD . ",
    "url": "/2025/#staff",
    "relUrl": "/#staff"
  },"37": {
    "doc": "Home",
    "title": "Prerequisites",
    "content": "6.5950/6.5951 is primarily intended for seniors, M.Eng, and PhD students who want to learn about how to design hardware processors with security as the primary goal. You should have a good understanding of basic computer architecture (i.e., a strong grasp of the material taught in 6.004) and C-programming experience. 6.5950/6.5951 is a 12-unit (3-0-9) subject. It is listed as an AUS/AAGS and TQE course. ",
    "url": "/2025/#prerequisites",
    "relUrl": "/#prerequisites"
  },"38": {
    "doc": "Home",
    "title": "Late Policy",
    "content": "Throughout the semester, you have 120 free late hours. You can use these free late hours if you are sick, have a busy week, or need more time to complete the lab. There are two ways that you could lose points due to late submissions. Firstly, after using all free late hours, there is 1% penalty per additional late hour. Secondly, if a single lab is submitted more than 120 hours late (even if part of them are free late hours), no credit will be awarded for that lab. Please note that long weekends (Feb 15–17, Apr 19–21) and spring break (Mar 22–30) are excluded from late hour calculations. In addition, extensions without penalty may be granted on a case-by-case basis with support from S3. Please email the staff to request an extra extension. If there are medical issues that require further accommodation, please contact the staff. ",
    "url": "/2025/#late-policy",
    "relUrl": "/#late-policy"
  },"39": {
    "doc": "Home",
    "title": "Collaboration Policy",
    "content": "Laboratory exercises should be completed individually, and the work you hand in must be your own. Copying another person’s work or allowing your work to be copied by others is a serious academic offense and will be treated as such. As a general rule, follow the MIT Academic Integrity Policy and, when in doubt, ask the course staff. Violations of this policy will be treated severely. Examples of permitted collaboration . | Allowed: Talk to a friend about a lab assignment and discuss at a high level how to go about completing the assignment. | Allowed: Ask a staff member for help if you are confused or stuck. | Allowed: After you’ve completed and submitted your own lab, help a friend debug their code solely by looking at their code and trying to identify problems with it. | . Examples of prohibited collaboration . | Not Allowed: Help a friend debug their code by bringing up your solution and comparing the two to identify differences. | Not Allowed: Using code from a friend who previously took the class as a starting point for completing your labs and then making some modifications to that code. | Not Allowed: Working together so closely that you are basically typing in your solutions side by side. | Not Allowed: Copying any portion of someone elses work even if you make some modifications to it. | Not Allowed: Sharing any portion of your code with someone else. | Not Allowed: Get help from a friend who is looking at their solutions while helping you. | . See the MIT Academic Integrity Policy. ",
    "url": "/2025/#collaboration-policy",
    "relUrl": "/#collaboration-policy"
  },"40": {
    "doc": "Home",
    "title": "Warning",
    "content": "You’ll learn how to attack computer systems in this class in order to better understand how to design defenses. Please don’t attack other people’s computers or information without their prior permission. As well as being a bad idea, it may be illegal or a violation of MIT network rules and can get you into serious trouble. ",
    "url": "/2025/#warning",
    "relUrl": "/#warning"
  },"41": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/2025/",
    "relUrl": "/"
  },"42": {
    "doc": "Labs",
    "title": "Labs",
    "content": "There will be 6 laboratory exercises given throughout the semester related to lecture content. | Lab | Difficulty | Due On | . | 0. C Crash Course (5%) | Easy | Thu, Feb 11 | . | 1. Website Fingerprinting (10%) | Easy | Thu, Feb 18 | . | 2. Cache Attacks (20%) | Hard | Thu, Mar 11 | . | 3. Spectre Attacks (15%) | Med | Thu, Mar 20 | . | 4. Rowhammer (15%) | Med | Thu, Apr 10 | . | 5. ASLR Bypasses (10%) | Easy | Thu, Apr 17 | . | 6 CPU Fuzzing (15%) | Med | Tue, May 6 | . | 7 CPU Verification (10%) | Easy | Tue, May 13 | . Your lab grade accounts for 85% (graduate version) or 97% (undergraduate version) of your final grade, with each lab weighted according to the ratios shown in the table above. Each lab is due at 11:59 PM. ",
    "url": "/2025/labs.html",
    "relUrl": "/labs.html"
  },"43": {
    "doc": "Labs",
    "title": "Lab Check-Offs",
    "content": "Over the course of the term, we will randomly select one of your labs from lab 2, 4, and 6.A for an in-person check-off (worth 3% of your total course grade). We will inform you whether you are selected for a lab on the day after the due of that lab. And you can pick a check-off time slot for the following week, (e.g., during office hours). During a check-off you will discuss your submission with the TA, describing your implementation and elaborating on your written answers. The goal of check-offs is to prevent cheating and make sure you actually learn. ",
    "url": "/2025/labs.html#lab-check-offs",
    "relUrl": "/labs.html#lab-check-offs"
  },"44": {
    "doc": "Labs",
    "title": "Submission Instructions",
    "content": "Labs will be submitted via GitHub Classroom, and accompanying reports will be submitted via Gradescope. GitHub . To access and submit lab materials, you will need to have a github.com account. For each lab, we will create a new repository for you on GitHub Classroom. To access the repository: . Check Piazza posts for the invitation link of Github Classroom. To clone the starter code from the repository: . git clone &lt;GITHUB CLASSROOM REPOSITORY LINK&gt; . However, if you have never used github on the machine you are running (i.e., either your own machine or our servers), you need following steps to authorize the machine to access GitHub: . | If you are using our server, connect using ssh (i.e., ssh username@&lt;servername&gt;.csail.mit.edu) | ssh-keygen -t rsa -b 4096 (note that if you already have an ssh key, you can skip this) | Press return until the command finishes. | cat ~/.ssh/id_rsa.pub (feel free to use an existing key if you have one) | Copy this and create a new ssh key on your GitHub account (instructions if you need help). | git clone &lt;GITHUB CLASSROOM REPOSITORY LINK&gt; | . To push your changes (submitting your work): . git add FILES_YOU_CHANGED git commit -m \"WHAT YOU CHANGED\" git push . GitHub classroom will snapshot the state of your repository at the due date (at 23:59:59), which we will use to grade your submission. Your repository will not be locked after that point, feel free to continue to push if we have allowed an extension for you. Gradescope . Each lab contains exercises and discussion questions. Type your answers to discussion questions in the markdown template provided in the starter code of each lab (report.md). Convert the markdown file to PDF (e.g., you can simply open the file on github.com and print it to PDF with your web browser) and upload the PDF file to Gradescope (prior to the submission deadline). ",
    "url": "/2025/labs.html#submission-instructions",
    "relUrl": "/labs.html#submission-instructions"
  },"45": {
    "doc": "Labs",
    "title": "Development Environment",
    "content": "For all our labs (and recitations, except lab 1), we will setup a user account for you on our lab machines, where the development environment has been properly setup. Check the email to get your username and the password. Alternative Docker Environment . Most our labs highly depend on the configurations of our physical machines (e.g., cache organization, DRAM model) and cannot be done locally on your own machine. However, for some labs, it is possible run the lab locally and we will provide a docker file in the repository to setup your environment. To use docker, you need to first understand two concepts: . | Docker Image: An image file storing all the pre-installed libraries (e.g., compilers, python libraries). | Docker Container: A running environment that is provisioned with a docker image and contains all the modifications you have made (e.g., install a new library). | . Then, you can use docker with follwing steps: . | Download the docker engine here. | In the root folder of a repository, where file Dockerfile and docker-compose.yml exist, use the command below to build the docker image, use the image to create a container, and run the container: docker compose up -d . | Enter the container and run bash with (env below is the name of the container that we specify in docker-compose.yml): docker compose exec env bash . | For your convenience, we mount the repository folder on your host machine into a folder named /gitRepo in the container (defined in docker-compose.yml). You could enter the folder and start to run the code: cd /gitRepo . | If you want to continue with the lab in another time, you could exit the container with ctrl-d. Then, pause and resume the container with: docker compose stop # Pause docker compose up -d # Resume . | When you are done with the lab, you could delete the container and the image with (Both commands will delete any modification you made to the container): docker compose down # Delete container but keep the image docker compose down --rmi all # Delete both container and image . | . You can find more document on using Docker Compose to manage docker images and containers here. ",
    "url": "/2025/labs.html#development-environment",
    "relUrl": "/labs.html#development-environment"
  },"46": {
    "doc": "Lecture Readings",
    "title": "Lecture Readings",
    "content": "* Indicates the resource requires MIT library login . | | Background Reviews and Related Books | Research Papers (mentioned in class) | Fun Readings and Videos | . | L01: Overview | 6.191 [6.004] slides: . | L01 The Digital Abstraction | L12 Memory Hierarchy | L13 Caches | L15 Pipelined Processors: Data and Control Hazards | L16 Operating Systems | L17 Virtual Memory 1 | L18 Virtual Memory 2 | L22 Modern Processor Architecture | . | | . | USENIX ATC '21/OSDI '21 Joint Keynote Address-It's Time for Operating Systems to Rediscover Hardware | . | . | L02: Side Channel Overview | | . | DAWG: A Defense Against Cache Timing Attacks in Speculative Execution Processors (Section I) | A retrospective on the VAX VMM security kernel. 1991 (Section VI-E) | . | . | Side Channel Security Youtube Channel | . | . | L03: Deep Dive of Cache Side Channels | | . | FLUSH+RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack | Last-Level Cache Side-Channel Attacks are Practical | Attack Directories, Not Caches: Side Channel Attacks in a Non-Inclusive World | . | . | EntryBleed: Breaking KASLR under KPTI with Prefetch | . | . | L04: Transient Execution Side Channels | . | 6.5900 [6.823] L06 Complex Pipelining Scoreboarding (Recording) (covered in the lecture, but if want to get more details about out-of-order execution) | . | . | On the Spectre and Meltdown Processor Security Vulnerabilities | Meltdown: Reading Kernel Memory from User Space | Spectre Attacks: Exploiting Speculative Execution | Speculative Load Hardening: A Spectre Variant #1 Mitigation Technique | MDS: Microarchitectural Data Sampling | . | | . | L05: Software-Hardware Contract | | . | Hardware-Software Contracts for Secure Speculation | ARM. DIT, Data Independent Timing | Intel. Data Operand Independent Timing Instruction Set Architecture (ISA) Guidance | FaCT: A DSL for Timing-Sensitive Computation | Secure, Precise, and Fast Floating-Point Operations on x86 Processors | BearSSL. Constant-time Crypto | . | | . | L06: Side-channel Mitigations (by Yuheng Yang) | | . | Complete Information Flow Tracking from the Gates Up | New Attacks and Defense for Encrypted-Address Cache | Speculative Taint Tracking (STT): A Comprehensive Protection for Speculatively Accessed Data | . | | . | L07: Physical Attacks (by Joseph Ravichandran) | . | 6.191 [6.004] L01 The Digital Abstraction | 6.191 [6.004] L06 Sequential Circuit | The Hardware Hacking Handbook* (Chapter 1, 5, 8, 13; The whole book includes many practical tips on how to carry out physical attacks by yourself) | Hacking the Xbox | . | . | Power Analysis Attacks: Revealing the Secrets of Smart Cards. 2007* | Building a high-performance, programmable secure coprocessor. 1999 (Section 4) | . | . | Talk on Supply Chain Attacks &amp; Verifiability | . | . | L08: Hardware Security Module (HSM) | . | Intel SGX Explained (Section 3.1-3.3, 4.1, 4.4-4.5) | Principles of Secure Processor Architecture Design* (Chaper 5 Hardware Root of Trust) | . | . | Building the IBM 4758 Secure Coprocessor. 2001 | Apple Platform Security (Page 5-96) | . | | . | L09: Rowhammer Attacks | . | Memory systems: cache, DRAM, disk.* (Chapter 10 DRAM Memory System Organization) | . | . | Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors | Flip Feng Shui: Hammering a Needle in the Software Stack | CLKSCREW: Exposing the Perils of Security-Oblivious Energy Management | Hertzbleed: Turning Power Side-Channel Attacks Into Remote Timing Attacks on x86 | The Story of Rowhammer - Keynote at Secure Hardware, Architectures, and Operating Systems Workshop (SeHAS) at the HiPEAC 2021 Conference | . | . | Exploiting the DRAM rowhammer bug to gain kernel privileges. Google Project Zero | . | . | L10: Rowhammer Mitigation + Reliability Solutions (by Peter Deutsch) | | . | Graphene: Strong yet Lightweight Row Hammer Protection | REGA: Scalable Rowhammer Mitigation with Refresh-Generating Activations | Hydra: Enabling Low-Overhead Mitigation of Row-Hammer at Ultra-Low Thresholds via Hybrid Tracking | Revisiting Residue Codes for Modern Memories | OpenTitan Website | OpenTitan Github | OpenTitan Talk in CHES 2022 | . | | . | L11: Hardware Support for Software Security | . | SoK: Eternal War in Memory | . | . | Smashing the Stack for Fun and Profit | An Introduction to CHERI | The Arm Morello Board | Virtual memory primitives for user programs. 1991 | Memory protection keys | Qualcomm. Pointer Authentication on ARMv8.3 Design and Analysis of the New Software Security Instructions | Armv8.5-A Memory Tagging Extension | Intel. Control-flow Enforcement Technology Specification (Section 1-3) | Control-flow integrity principles, implementations, and applications. 2005 | . | . | xkcd. HeartBleed Explanation | . | . | L12: Fuzzing and Bug Finding | | . | Computational aspects of the Pentium affair. 1995 | Fuzzing Hardware Like Software | SPECS: A Lightweight Runtime Mechanism for Protecting Software from Security-Critical Processor Bugs | Bug Attacks | HardFails: Insights into Software-Exploitable Hardware Bugs | The Art, Science, and Engineering of Fuzzing: A Survey | Branch History Injection: On the Effectiveness of Hardware Mitigations Against Cross-Privilege Spectre-v2 Attacks | SiliFuzz: Fuzzing CPUs by proxy | . | . | Breaking the x86 Instruction Set. BlackHat | Intel Pentium FPU glitch. 1994 | A Stitch In Time Saves Nine: A Stitch In Time Saves Nine: A Case Of Multiple OS Vulnerability | Riding the Fuzzing Hype Train (RAID'21 Keynote) | . | . | L13: Formal Verification for Hardware Security | | . | The Complexity of Theorem-Proving Procedures. 1971 | A Machine Program for Theorem-Proving. 1962 | GRASP: A Search Algorithm for Propositional Satisfiability. 1999 | End-to-End Verification of ARM Processors with ISA-Formal. 2016 | . | | . | L14: Trusted Execution Environment (TEE) | . | Intel SGX Explained (Section 5 SGX Programming Model) | . | . | SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments | AMD Secure Encrypted Virtualization (SEV) | Protecting VM Register State With SEV-ES | AMD SEV-SNP | Keystone: An Open Framework for Architecting Trusted Execution Environments | RISC-V Privileged Instructions (Section 3.6) | Arm Confidential Compute Architecture (Arm Website) | Intel Trust Domain Extensions (TDX) | . | | . ",
    "url": "/2025/lectureReadings.html",
    "relUrl": "/lectureReadings.html"
  },"47": {
    "doc": "Lecture Readings",
    "title": "Lecture Readings",
    "content": " ",
    "url": "/2025/lectureReadings.html",
    "relUrl": "/lectureReadings.html"
  },"48": {
    "doc": "Paper Discussion",
    "title": "Paper Discussion",
    "content": "In each discussion session, we will discuss 5 papers around a same topic. The discussion of each paper will be led by 2 students (who take the graduate version of the course, i.e., 6.5950). Throughout the semester, each student will only lead the discussion once. The papers to be discussed are selected from top security and computer architecture conferences, covering broad hardware security topics representing the state of the art. For the presenters, please check Piazza posts for knowing when you will present which paper. As you prepare for the presentation, make sure to refer to our detailed paper reading guidance for how to read a hardware security paper, what is required for the presentation, and how your presentation will be graded. For the audience, we encourage you to pick a paper to read before each discussion session and ask questions during the Q&amp;A of that paper, as well as other papers. Based on the quality of the questions, we will give bonus points toward your final grades. Audience and presenters will also be invited to vote how much you like each paper (e.g., should it get a “Best Paper Award”?). It would be fun and we are curious about your opinions on them! . ",
    "url": "/2025/paperDiscussion.html",
    "relUrl": "/paperDiscussion.html"
  },"49": {
    "doc": "Paper Readings Guidance",
    "title": "How to read a research paper?",
    "content": "We believe learning how to read a research paper is an important component of this class. There exists many materials describing how to read a paper. The following two recommended readings discussed a “three-pass approach”, and talked about what questions you should think about while reading a research paper. If you have never read a research paper before, we suggest you go through these two articles first to get a rough idea of how to approach a paper. They also provide useful note-taking tips. References . | How to Read a Paper; S. Keshav; ACM SIGCOMM Computer Communication Review; 2007. | How to Read an Engineering Research Paper; William G. Griswold. | . We provide an adapted and succinct version of how to read a hardware security paper for the SHD course below. The first pass: . For your first pass, read the following items and skip the others: . | Title and abstract | The introduction section | Section and subsection titles (just the titles, not the content) | Related work section and the conclusion. | . After this pass, you should be able to answer the following questions: . | Category: What type of paper is this? Is it an attack paper, a defense paper, or an analysis paper? | Context (background and related work): . | We might have discussed some background materials in class. Try to think about whether there exists any background gap for the other students in the class to understand this paper: what background materials we have NOT covered which you have to include in your presentation. | Get an idea about existing work that this paper relates to. This step is to get your prepared for critical thinking of this paper. If it is an attack paper, what are the other existing attacks that target the same threat model? If it is a defense paper, what are the other existing defenses that share a similar security goal as this paper? | . | Contributions: What are claimed as the paper’s main contributions? | . The second pass: . Read the paper with greater care, but ignore details such as proofs. The goal is to grasp the main content of the paper. Here are a few tips on how to zoom in. | Look carefully at the figures, diagrams, and other illustrations in the paper. If you can thoroughly understand the important figures in the main section, you are on the right track. If you find things are fuzzy, you will then need to read the text that explain these figures/diagrams multiple times to decipher the content. | A useful tip is to look for videos related to this paper online (sometimes conferences post lightning talks or full talks of the accepted papers on Youtube or conference websites). Observe how the authors explain their work. This will help you understand the key contributions better. Moreover, seeing how the idea being presented in a different format other than pure text will help you structure and design your presentation slides. Just be aware that, conference presentations usually focus on highlighting the contributions, and rarely talk about limitations of the work. | . As you read through the paper, attempt to answer the following questions (from Griswold’s article and adapted for hardware security papers): . | What are the background and motivations for this work? Put the work into context, try to relate to materials that we have covered in class, fill any knowledge gap that is needed for your classmates to understand the work. | What is the proposed idea of this paper? Here it is very important for you to distinguish between high-level ideas and implementation details. Within the limited amount of presentation time, you need to pick the key components of the idea proposed by this paper and focus on the most important things to share with your fellow classmates. | What is the work’s evaluation of the proposed solution? What argument, implementation, and/or experiment makes the case for the value of the ideas? It should be roughly easy to identify the evaluation section and read through what the authors did to validate their idea. | What are future directions for this research? What questions are you left with? What is your take-away message from this paper? . | We recommend the students try to connect the paper with their own background (if any) | We like to hear critiques from the students. Last year, a team did their presentation by almost toating the paper for 10 min. We (the course staffs and the students) all enjoyed that presenation a lot. Unfortunately, we cannot share the recording of that particular presentation with you. | . | . The third pass (optional for this course): . | The key to the third pass is to attempt to virtually re-implement the paper: that is, making the same assumptions as the authors, re-create the work. By comparing this re-creation with the actual paper, you can easily identify not only a paper’s innovations, but also its hidden failings and assumptions. This is usually needed when you are reviewing the paper as a program committee member. | You should identify and challenge every assumption in every statement. During this pass, you should also jot down ideas for future work. | . ",
    "url": "/2025/paperReadingGuidance.html#how-to-read-a-research-paper",
    "relUrl": "/paperReadingGuidance.html#how-to-read-a-research-paper"
  },"50": {
    "doc": "Paper Readings Guidance",
    "title": "How will we run the discussion session?",
    "content": "During each paper discussion session, we will keep track of the time for each paper. If you run out of time, you will be interrupted and end up not finishing your presentation. So make sure to practice your presentation ahead of time. | Presentation: 12 min . | Paper summary (motivation, proposed idea, evaluation): ~8 min | Paper critiques (strengths, weaknesses, your thoughts, future work): ~4 min | . | Class Q&amp;A: 2 min | Class vote: 1 min (if the presenters decide to nominate the paper for a best paper award) | . Timing is very tight – please come to class on time! . ",
    "url": "/2025/paperReadingGuidance.html#how-will-we-run-the-discussion-session",
    "relUrl": "/paperReadingGuidance.html#how-will-we-run-the-discussion-session"
  },"51": {
    "doc": "Paper Readings Guidance",
    "title": "How will your presentation be graded?",
    "content": "Now comes what you care the most, i.e., how we will grade the presentation. First, let’s clarify the grading procedure. Your presentation will be rigorously graded by four persons: the instructor and the three TAs. Every judge’s score weights equally. The average score will be your final grade. Second, we look for three aspects of the presentation. | Your understanding of the paper, based on the content of your slides. | The clarify of the explanation for technical concepts and details, based on the design of your slides. | The oral presentation quality. | . The judges will give letter grades for items 1 and 2. The letter grades are S, A, B, D. | S: spectacular, award level | A: good, but not impressive | B: fair, can be improved | D: I do not think the presenters put much efforts into it… | . The final grade is computed by multiplying the score for the slide content and the score for the design of slides. As such, if you put enough efforts in understanding the paper and putting together the slides, you should get a satisfying score. You may notice that we do not count item 3 (the oral presentation quality) into your grade. The reason is that we want the paper discussion session to be a welcoming environment for the students to practice public speech and learn from each other. We understand that some students may be shy, and international students might have some language barriers. Therefore, the course staff have made the decision to not include the oral part into grading. Instead, we will give out some small prizes (which has nothing to do with course grades) to award excellent presentations. ",
    "url": "/2025/paperReadingGuidance.html#how-will-your-presentation-be-graded",
    "relUrl": "/paperReadingGuidance.html#how-will-your-presentation-be-graded"
  },"52": {
    "doc": "Paper Readings Guidance",
    "title": "Content of Slides (Understanding the paper)",
    "content": "We have the following requirements for the content of the slides. | Background and motivation: the presentation should include sufficient background for the audience to understand the technical content. Try to connect to the materials that we have covered in class. Fill in any knowledge gap. | Key contribution: the presentation should provide an intuitive high-level summary of the key contributions, assited with illustrative examples/explanations to guide the audience to thoroughly understand the proposed techniques. A good presentation should pick out the most important things and spend sufficient time going through to convey the concepts or techniques to the audience. | Evaluation: summarize the main evaluation results, explain why the authors can get such results, and highlights important takeaway messages. | Critiques: comment on the strengths and weaknesses of the paper, focusing on the technical aspects. | . ❌ What should you avoid when summarizing a paper? . We have collected a few bad examples so you can also check to makes sure to avoid these pitfalls. Background and motivation: . | Delve into the main contribution directly without providing the background of the work. The audience is left clueless about why the authors even need to pay the efforts to write this paper. | Forget to explain some important terminology or acronym, since you are too familiar with them as your spend a few hours reading the paper. But your classmates have not read the paper, so they will be confused throughout the presentation if you repeately use terms they can only guess the meaning of. | . Key contribution: . | In the slide, copy the concise and high-level description the authors put in the introduction section or the first paragraph of the main section, without providing extra explanation of what this sentence mean. | Try to cover content from every section in the paper. This is not feasible. Note these technical papers are usually dense, and no one can have the capability to digest a 12-page paper within 10 minutes. Often, less is more. So you need to spend a lot of time carefully thinking and picking which sections should be included in your presentation. | Refer to undefined terms. Sometimes the authors may want to come up with fancy names or acronomy for some components of their design or technique. You should not indulge yourself to use them freely, meaning mentioning them without providing a definition, since your classmates will get lost. Overall, the articulation of the proposed technique should be self-contained. | Show a pseudocode or a figure without explaining what the setup is and what this code/figure does. A useful thumb of rule is that, anything you decide to include in the slides, you should talk through them so the audience can fully grasp what they mean, rather than “oh… the only impression I have is that there are some code…” | . Evaluation: . | Go through every figure/plot in the evaluation section. This is not a good idea, since not all the evaluation results matter equally. Most of these papers went through a tough peer review process, where the reviewers may suggest extra experiments for the authors to further validate the design to make the paper more complete. You need to pick the important ones to present. | Only present the results without explaining why the authors obtain the results or what lessons we can learn from these results. | . Critiques: . | The paper is not well written. This is not a very useful comment for the audience since they will not read the paper. Better to focus on technical comments. | . ",
    "url": "/2025/paperReadingGuidance.html#content-of-slides-understanding-the-paper",
    "relUrl": "/paperReadingGuidance.html#content-of-slides-understanding-the-paper"
  },"53": {
    "doc": "Paper Readings Guidance",
    "title": "Design of Slides (Explaining the paper)",
    "content": "We provide the following excellent examples for your inspiration. Both teams won the TA-chosen presentation awards last year. What you can easily see from the videos is that both teams leveraged figures and animations to assist the concepts they try to convey. | LLC is Practical by Baltasar Dinis and Rem Yang (slides, video) | Flip Feng Shui by Daniël Trujillo (slides, Flip Feng Shui) | . To help you prepare your presentation, we also provide a few bad examples crafted by the TAs. ",
    "url": "/2025/paperReadingGuidance.html#design-of-slides-explaining-the-paper",
    "relUrl": "/paperReadingGuidance.html#design-of-slides-explaining-the-paper"
  },"54": {
    "doc": "Paper Readings Guidance",
    "title": "Paper Readings Guidance",
    "content": " ",
    "url": "/2025/paperReadingGuidance.html",
    "relUrl": "/paperReadingGuidance.html"
  }
}
